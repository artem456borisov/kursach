{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e255a8-cc20-4020-a69b-49d4371b6365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7a76a61ef34434b7da0ed2ca99d6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from flash_attn import flash_attn_qkvpacked_func, flash_attn_func\n",
    "\n",
    "model_name = 'huggyllama/llama-7b'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, pad_token = '</s>')\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = \"right\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "     attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name, \n",
    "#     torch_dtype=torch.bfloat16, \n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name, \n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     output_attentions=False,\n",
    "#     output_hidden_states = True,\n",
    "#     device_map=\"auto\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136db77a-5785-4c15-9628-f6ba59c4442e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 2], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "216d95cb-0b64-4fc4-88a3-00856e4d3874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61acd1df-af26-45f9-ae02-c60f50c5f859",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 31 18:54:38 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.172.01   Driver Version: 450.172.01   CUDA Version: 12.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-PCIE-40GB      On   | 00000000:65:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    39W / 250W |  13302MiB / 40537MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     81464      C   ...nvs/graph_venv/bin/python    13300MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c39038b5-59c9-4b57-a570-135c8e22b857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "# dataset names in low-case\n",
    "task_name = [\"simplear\", \n",
    "             \"rwsd\", \n",
    "             \"rumultiar\", \n",
    "             \"rumodar\", \n",
    "             \"rutie\", \n",
    "             \"rummlu\", \n",
    "             \"ruhumaneval\", \n",
    "             \"ruhatespeech\", \n",
    "             \"rcb\", \n",
    "             \"lcs\", \n",
    "             \"bps\", \n",
    "             \"rudetox\", \n",
    "             \"ruethics\", \n",
    "             \"ruhhh\", \n",
    "             \"use\", \n",
    "             \"parus\", \n",
    "             \"mathlogicqa\", \n",
    "             \"ruopenbookqa\", \n",
    "             \"ruworldtree\", \n",
    "             \"multiq\", \n",
    "             \"chegeka\"]\n",
    "\n",
    "i = 5\n",
    "DATASET_PATH = \"ai-forever/MERA\"\n",
    "DATASET_NAME = f\"{task_name[i]}\"\n",
    "df = load_dataset(DATASET_PATH, \n",
    "                  DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7947d9ba-eb6d-4c37-817e-87edd8c2761b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train:                                           instruction  \\\n",
       "    0   Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "    1   Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "    2   Ниже приведен вопрос на определенную профессио...   \n",
       "    3   Найдите правильный ответ на вопрос по теме {su...   \n",
       "    4   Дайте ответ на задание по теме {subject}:\\n{te...   \n",
       "    5   Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "    6   Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "    7   Ниже приведен вопрос на определенную профессио...   \n",
       "    8   Найдите правильный ответ на вопрос по теме {su...   \n",
       "    9   Дайте ответ на задание по теме {subject}:\\n{te...   \n",
       "    10  Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "    11  Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "    12  Ниже приведен вопрос на определенную профессио...   \n",
       "    13  Найдите правильный ответ на вопрос по теме {su...   \n",
       "    14  Дайте ответ на задание по теме {subject}:\\n{te...   \n",
       "    15  Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "    16  Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "    17  Ниже приведен вопрос на определенную профессио...   \n",
       "    18  Найдите правильный ответ на вопрос по теме {su...   \n",
       "    19  Дайте ответ на задание по теме {subject}:\\n{te...   \n",
       "    \n",
       "                                                   inputs outputs  \\\n",
       "    0   {'text': 'В какой из этих двух ситуаций действ...       B   \n",
       "    1   {'text': 'В какой из этих двух ситуаций действ...       C   \n",
       "    2   {'text': 'В какой из этих двух ситуаций действ...       C   \n",
       "    3   {'text': 'В какой из этих двух ситуаций действ...       A   \n",
       "    4   {'text': 'В какой из этих двух ситуаций действ...       C   \n",
       "    5   {'text': 'В какой из этих двух ситуаций действ...       B   \n",
       "    6   {'text': 'Какой из нижеперечисленных терминов ...       C   \n",
       "    7   {'text': 'Ad antiquitatem \" - это особый вид',...       B   \n",
       "    8   {'text': 'Audi предложила нам расширить список...       D   \n",
       "    9   {'text': '_Ad \"rumenam_ \" - это', 'option_a': ...       B   \n",
       "    10  {'text': '_Ad lazarum_ \" - это особый вид', 'o...       D   \n",
       "    11  {'text': '____________ - это набор практик, ко...       A   \n",
       "    12  {'text': '____________ также является формой с...       A   \n",
       "    13  {'text': '_______________ используются в проце...       C   \n",
       "    14  {'text': '________________ происходят там, где...       C   \n",
       "    15  {'text': 'Альтман считает, что существуют знач...       D   \n",
       "    16  {'text': 'Аристотель определяет добродетель ка...       B   \n",
       "    17  {'text': 'База данных информации, которая подд...       A   \n",
       "    18  {'text': 'Барон цитирует краткое изложение пок...       C   \n",
       "    19  {'text': 'Биоцентризм - это точка зрения, согл...       C   \n",
       "    \n",
       "                                             meta  \n",
       "    0      {'domain': 'moral_scenarios', 'id': 0}  \n",
       "    1      {'domain': 'moral_scenarios', 'id': 1}  \n",
       "    2      {'domain': 'moral_scenarios', 'id': 2}  \n",
       "    3      {'domain': 'moral_scenarios', 'id': 3}  \n",
       "    4      {'domain': 'moral_scenarios', 'id': 4}  \n",
       "    5      {'domain': 'moral_scenarios', 'id': 5}  \n",
       "    6     {'domain': 'machine_learning', 'id': 6}  \n",
       "    7    {'domain': 'logical_fallacies', 'id': 7}  \n",
       "    8       {'domain': 'moral_disputes', 'id': 8}  \n",
       "    9    {'domain': 'logical_fallacies', 'id': 9}  \n",
       "    10  {'domain': 'logical_fallacies', 'id': 10}  \n",
       "    11          {'domain': 'marketing', 'id': 11}  \n",
       "    12          {'domain': 'marketing', 'id': 12}  \n",
       "    13          {'domain': 'marketing', 'id': 13}  \n",
       "    14          {'domain': 'marketing', 'id': 14}  \n",
       "    15     {'domain': 'moral_disputes', 'id': 15}  \n",
       "    16     {'domain': 'moral_disputes', 'id': 16}  \n",
       "    17          {'domain': 'marketing', 'id': 17}  \n",
       "    18     {'domain': 'moral_disputes', 'id': 18}  \n",
       "    19     {'domain': 'moral_disputes', 'id': 19}  \n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'inputs', 'outputs', 'meta'],\n",
       "        num_rows: 961\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e03d6d9e-2c76-4b36-8b07-c8c4f03cee4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>inputs</th>\n",
       "      <th>outputs</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Реши задачу по программированию\\n{function}</td>\n",
       "      <td>{'function': 'from typing import List\n",
       "\n",
       "\n",
       "def ha...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>{'id': 0, 'canonical_solution': '\n",
       "\n",
       "    sorted_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Реализуй функцию(ии) на языке Python\\n{function}</td>\n",
       "      <td>{'function': 'from typing import List\n",
       "\n",
       "\n",
       "def se...</td>\n",
       "      <td>[['()'], ['(())'], ['((()))', '()'], ['()', '(...</td>\n",
       "      <td>{'id': 1, 'canonical_solution': '\n",
       "\n",
       "    cnt, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Напишите программу по строке документации\\n{fu...</td>\n",
       "      <td>{'function': '\n",
       "\n",
       "def truncate_number(number: fl...</td>\n",
       "      <td>[0.9999900000000252, 0.3333333, 0.0, 0.5, 0.5,...</td>\n",
       "      <td>{'id': 2, 'canonical_solution': '\n",
       "\n",
       "    return ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Необходимо реализовать логику на языке Python ...</td>\n",
       "      <td>{'function': 'from typing import List\n",
       "\n",
       "\n",
       "def be...</td>\n",
       "      <td>[False, False, False, True, True, True, True, ...</td>\n",
       "      <td>{'id': 3, 'canonical_solution': '\n",
       "    account ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0        Реши задачу по программированию\\n{function}   \n",
       "1   Реализуй функцию(ии) на языке Python\\n{function}   \n",
       "2  Напишите программу по строке документации\\n{fu...   \n",
       "3  Необходимо реализовать логику на языке Python ...   \n",
       "\n",
       "                                              inputs  \\\n",
       "0  {'function': 'from typing import List\n",
       "\n",
       "\n",
       "def ha...   \n",
       "1  {'function': 'from typing import List\n",
       "\n",
       "\n",
       "def se...   \n",
       "2  {'function': '\n",
       "\n",
       "def truncate_number(number: fl...   \n",
       "3  {'function': 'from typing import List\n",
       "\n",
       "\n",
       "def be...   \n",
       "\n",
       "                                             outputs  \\\n",
       "0  [False, False, False, False, False, False, Fal...   \n",
       "1  [['()'], ['(())'], ['((()))', '()'], ['()', '(...   \n",
       "2  [0.9999900000000252, 0.3333333, 0.0, 0.5, 0.5,...   \n",
       "3  [False, False, False, True, True, True, True, ...   \n",
       "\n",
       "                                                meta  \n",
       "0  {'id': 0, 'canonical_solution': '\n",
       "\n",
       "    sorted_...  \n",
       "1  {'id': 1, 'canonical_solution': '\n",
       "\n",
       "    cnt, gr...  \n",
       "2  {'id': 2, 'canonical_solution': '\n",
       "\n",
       "    return ...  \n",
       "3  {'id': 3, 'canonical_solution': '\n",
       "    account ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'].to_pandas().head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a33d1400-1aeb-4fe6-8c9d-c466be81690e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = df['train'].to_pandas().loc[0]\n",
    "prompt = doc[\"instruction\"].format(**doc[\"inputs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d266f5-883e-4578-841c-0a995b407400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moral_scenarios'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rummlu evaluation by domain:\n",
    "domain = doc[\"meta\"][\"domain\"]\n",
    "domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9042ced-1b95-4ed4-8f27-71539511bbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Задание содержит вопрос по теме Философия и 4 варианта ответа A, B, C, D, из которых только один правильный.\n",
      "В какой из этих двух ситуаций действующее лицо, использующее местоимения \"я\"/\"меня\"/\"мой\", нарушает нормы морали, общепринятые в США по состоянию на 2020 год? Ситуация 1 | Я оторвал голову детской игрушке. Ситуация 2 | Я узнал, что моей сестре нравится один мальчик, она не хотела, чтобы он знал, и я сохранил это в тайне.\n",
      "A Нарушает, Нарушает\n",
      "B Нарушает, Не нарушает\n",
      "C Не нарушает, Нарушает\n",
      "D Не нарушает, Не нарушает\n",
      "Запишите букву правильного ответа\n",
      "Ответ:\n"
     ]
    }
   ],
   "source": [
    "# model query\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae81c604-ec6b-4864-8c7d-f30519321b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moral_scenarios'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[\"meta\"][\"domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82235a3-7254-49f4-8d8f-bae8a68cfc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a030b68-4f22-4b5e-9224-a195694528db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/graph_venv/lib/python3.9/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jovyan/.mlspace/envs/graph_venv/lib/python3.9/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 235, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = torch.tensor(tokenizer(prompt)['input_ids']).long().unsqueeze(0).to(device)\n",
    "out = model.generate(tokens).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57f6866c-bfe0-4154-8e23-ab1f9b2bee04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/graph_venv/lib/python3.9/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 256, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = torch.tensor(tokenizer(prompt)['input_ids']).long().unsqueeze(0).to(device)\n",
    "out = model.generate(tokens).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf0945ed-9eaf-4315-ad57-bc01c8e99199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = out.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1a0b3e6-cb48-4e96-9133-03b0dc707cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Задание содержит вопрос по теме Философия и 4 варианта ответа A, B, C, D, из которых только один правильный.\n",
      "В какой из этих двух ситуаций действующее лицо, использующее местоимения \"я\"/\"меня\"/\"мой\", нарушает нормы морали, общепринятые в США по состоянию на 2020 год? Ситуация 1 | Я оторвал голову детской игрушке. Ситуация 2 | Я узнал, что моей сестре нравится один мальчик, она не хотела, чтобы он знал, и я сохранил это в тайне.\n",
      "A Нарушает, Нарушает\n",
      "B Нарушает, Не нарушает\n",
      "C Не нарушает, Нарушает\n",
      "D Не нарушает, Не нарушает\n",
      "Запишите букву правильного ответа\n",
      "Ответ:</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b82df17d-cbe8-4524-bee6-626e4f99b4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from src.dataset import MERA_dataset, Collator\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device='cuda'\n",
    "class MERA_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.prompt = df['instruction']\n",
    "        self.inputs = df['inputs']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label, label_names = pd.factorize(np.array(df['outputs']))\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        prompt = self.prompt[idx].format(**self.inputs[idx])\n",
    "        label = self.label[idx]\n",
    "        #prompt = self.tokenizer.encode_plus(prompt,max_length = 256, truncation=True, padding='max_length', return_tensors='pt').to(device)\n",
    "        prompt = self.tokenizer.encode_plus(prompt, return_tensors='pt',\n",
    "                                            padding= 'max_length', max_length= 512, truncation= True\n",
    "                                            \n",
    "                                           ).to(device)\n",
    "        prompt = {k:v.flatten() for k,v in prompt.items()}\n",
    "        label = torch.tensor([label]).to(device)\n",
    "        item = {**prompt}\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "class Collator():\n",
    "    def __init__(self, tokenizer, tokenizer_kwargs):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer_kwargs = tokenizer_kwargs\n",
    "    def __call__(self, batch):\n",
    "        q, asw = zip(*batch)\n",
    "        q = self.tokenizer(q, **self.tokenizer_kwargs)\n",
    "        asw = torch.Tensor(asw)\n",
    "        return q, asw\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4bdf579-83af-4b72-a0af-1315a2d6a6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['train'] = df['train'].to_pandas()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cce3b414-cc6e-47e7-ba1d-9b6e4c83e5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.return_tensors= 'pt'\n",
    "tokenizer.padding= 'max_length'\n",
    "tokenizer.max_length= 1024\n",
    "tokenizer.truncation= True\n",
    "data = MERA_dataset(df['train'], tokenizer)\n",
    "full_dataloader = torch.utils.data.DataLoader(data, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17937e8c-e28f-4278-b195-3d52d4eecf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(full_dataloader):\n",
    "        outputs = model.generate(**batch, max_new_tokens=5)\n",
    "        outputs = tokenizer.batch_decode(outputs)\n",
    "        outputs = [i[-6:-1] for i in outputs]\n",
    "        preds.extend(outputs)\n",
    "end=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5c467f2-b3fa-4f81-bdc0-b82be34050cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(full_dataloader):\n",
    "        outputs = model.generate(**batch, max_new_tokens=5)\n",
    "        # shapes = outputs.input_ids.shape[1]\n",
    "        outputs = outputs[:, 512:]\n",
    "        outputs = tokenizer.batch_decode(outputs)\n",
    "        # outputs = [i[-6:-1] for i in outputs]\n",
    "        preds.extend(outputs)\n",
    "end=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "110216fe-0213-42ed-826d-ec24952a26f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e8b7b2a-c5b7-48b3-9d04-5db33f7a0aeb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     1,  2372, 29977,\n",
       "            956,   730, 12318, 24178,  1685,  7616,   665, 29309, 29935,   733,\n",
       "           2399,  1488, 13038, 25885,  2885, 29970,   490, 27341,  3849,  7380,\n",
       "           1498, 29889,   939, 22285,  1685,  1521,   676,  1077,  1668,  1911,\n",
       "            730, 15302,  3288,  1864,  3180, 29951,  5944,  2771, 25567,  1868,\n",
       "           8935,   641, 28375, 29901,   319, 29892,   350, 29892,   315,  7082,\n",
       "            360, 10642,  1447,  9518, 25163,  2430, 11779, 29970, 29935,   821,\n",
       "           2332,   313, 29919,  6395,  4190,  6122,  1909, 16789,  8203,  3048,\n",
       "            811,  1086,  4364,   467,    13, 30031, 29910,  6887, 12442,   811,\n",
       "           1086,  1257,  6697, 29932,   551, 29919,  1866,   843, 11567, 25511,\n",
       "           2332,  1291,   644,  9624,  8685,   477,   490,  7215,   477,   730,\n",
       "          29892, 18421,  4570, 24141, 27359, 29892,  4281,    13, 29909,   469,\n",
       "          29982, 13921, 29246,  3102,  3327,   846,  4394,  3550, 25366,   490,\n",
       "            614,  2194,   507,  4896,  2430,  3485, 29412,  5274, 29988, 29889,\n",
       "             13, 29933,   614,  1802, 13782,  1755, 29082,   507, 12290, 20356,\n",
       "            676,   469, 29982, 13921,  8847,  3378,  1257,   614,  1802, 13782,\n",
       "           1587,   469, 29982, 14308,  5413,  4460,  9054,   717, 29889,    13,\n",
       "          29907,  3807, 19823, 30002,  1868,  1447,  5945,  2019, 20302,  1538,\n",
       "            733, 11414, 29975,  1263,  4199,  1695, 17859,  1755,   469, 29982,\n",
       "          14308, 29889,    13, 29928,   469, 29982, 19972,   448,  6408,  6495,\n",
       "           9077,  1538, 19524, 11372, 29892, 10642,   606,  6231,  2583, 12395,\n",
       "          29889,    13, 30038, 29932,  7616, 29901],\n",
       "         [    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2,     2,     2,     1,\n",
       "           8371, 29977,   730,  1685,  7616,   665, 27341,  1755,   733,  2399,\n",
       "           1488, 13038, 25885,  2885, 29970, 29901,    13, 30031, 29917, 29904,\n",
       "          23537,   641, 21346,   448,  6408,  2721, 10546,   754,   587,  1587,\n",
       "          29892,  1778, 23405, 20935,    13, 29909, 25918,  4190,  3029, 19391,\n",
       "           3828, 29892,  5055,   840, 17648, 23380,  5588, 29959,  2569,  8639,\n",
       "           4470, 24692, 13139, 29892,   448,  6408, 28995, 29889,    13, 29933,\n",
       "           6495,   606, 15302,  3212, 20984,  3029, 19391,  3828,  5055,   840,\n",
       "           4394, 23380,  5588, 29959,  2569,  8639,  4470, 24692, 13139, 29889,\n",
       "             13, 29907,  6495,  4438, 19455, 19391,  3828, 29892,   733,  1130,\n",
       "            693,  1382, 16642,  4438, 19455, 29892,  5055,   840,  4394, 23380,\n",
       "           5588, 29959,  2569,  8639,  4470, 24692, 13139, 29889,    13, 29928,\n",
       "           8838,  8535,  4228,  9440,  1225,   989, 23380, 19370,  2569,  8639,\n",
       "           1868, 24692,  2019,  9960,  9480,  2352,   551,  1325, 18773, 29982,\n",
       "            490,  3485,  1844, 11244, 20153, 12671,  2082,  8816,   843,   464,\n",
       "           5395, 29889,    13, 30038, 29932,  1521,  4816,  1186, 27341,  7506,\n",
       "          14367,  3180, 11691, 29892,  1685,  5551,   684, 30005, 19485,  1186,\n",
       "          12318,   693,  8103,  8935,   641,   745,  1500,  1685,  1521,   676,\n",
       "          29889,    13, 30038, 29932,  7616, 29901]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1268882-c5ed-49d0-85f9-2cab8607f84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lol = 'heltop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f63619cd-d571-4571-a4ab-36b5838d2b17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hel'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3e4f68a-c274-4d6c-8947-5ccb9bc06340",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A\\nЗадание',\n",
       " 'A\\nВ какой',\n",
       " 'A\\nВ первой',\n",
       " 'A\\nВ какой',\n",
       " 'C\\nThe first situation',\n",
       " 'A\\nЗадание',\n",
       " 'B\\nКакой из',\n",
       " 'A\\nThe term \"',\n",
       " 'A\\nAudi пред',\n",
       " '_B_\\nО',\n",
       " 'A\\nВыбор',\n",
       " 'B Социальный ве',\n",
       " 'B\\n______________',\n",
       " 'C\\n_______________',\n",
       " 'B\\nОтвет',\n",
       " 'C\\nАльт',\n",
       " 'C\\nАристо',\n",
       " 'C\\nПрило',\n",
       " 'C\\nАли Су',\n",
       " 'B\\nThe bio-']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67677123-2961-42cc-8a03-11ddb85136bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a06c3-66ee-46c0-aca7-0e331fc5e6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f0af395-53eb-4ba3-8bfa-efb74a1cabc2",
   "metadata": {},
   "source": [
    "Time Base Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d01af02-12b0-4825-93c0-fe64a924cdae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330.0001573562622"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975fbbe-2c17-46ef-b3ba-c36492e54e5a",
   "metadata": {},
   "source": [
    "Accuracy Base Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a439db4-8877-440d-8957-f709e13abe95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81464/3186560661.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  (np.array(preds) == df['train']['outputs']).sum()/len(preds)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (20,), (10,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(preds)\n",
      "File \u001b[0;32m~/.mlspace/envs/graph_venv/lib/python3.9/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.mlspace/envs/graph_venv/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.mlspace/envs/graph_venv/lib/python3.9/site-packages/pandas/core/series.py:5803\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5800\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   5801\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 5803\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.mlspace/envs/graph_venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:323\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# TODO: make this treatment consistent across ops and classes.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m#  We are not catching all listlikes here (e.g. frozenset, tuple)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m#  The ambiguous case is object-dtype.  See GH#27803\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lvalues) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rvalues):\n\u001b[0;32m--> 323\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    325\u001b[0m         )\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    328\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    330\u001b[0m ):\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(lvalues, rvalues)\n",
      "\u001b[0;31mValueError\u001b[0m: ('Lengths must match to compare', (20,), (10,))"
     ]
    }
   ],
   "source": [
    "(np.array(preds) == df['train']['outputs']).sum()/len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49511bef-0fcd-4a6f-802e-035c8b985b3d",
   "metadata": {},
   "source": [
    "Time with flash attention 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd0de2c4-ac94-4fd1-a07b-be4046a6f2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331.42977809906006"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47039e0b-af6f-44a8-80df-934b2c9075d4",
   "metadata": {},
   "source": [
    "Accuracy with flash attention 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbbc8128-2f73-4f44-a994-3db4afd298c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.267018837835144"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(preds) == df['train']['outputs']).sum()/len(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-graph_venv]",
   "language": "python",
   "name": "conda-env-.mlspace-graph_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

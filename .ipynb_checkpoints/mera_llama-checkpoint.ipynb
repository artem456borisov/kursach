{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e255a8-cc20-4020-a69b-49d4371b6365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f2ad19f0ce48079f0c136eea643ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from flash_attn import flash_attn_qkvpacked_func, flash_attn_func\n",
    "\n",
    "model_name = 'huggyllama/llama-7b'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "    use_flash_attention_2=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216d95cb-0b64-4fc4-88a3-00856e4d3874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaFlashAttention2(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39038b5-59c9-4b57-a570-135c8e22b857",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2557ef86bf3c42e1887d69341dc78c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/135k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3191812cf6f14c46b79a4855bcc331d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cd00218a7b4db295898795548599ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f966c95e3434767848b1c94019c9626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/845k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0715a6393b4fae996e16c571af87aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f769972b6741da89e0713b1eeaf0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10033 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8070f6ad4b434bc6b4a3975a842ef238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/961 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "# dataset names in low-case\n",
    "task_name = [\"simplear\", \n",
    "             \"rwsd\", \n",
    "             \"rumultiar\", \n",
    "             \"rumodar\", \n",
    "             \"rutie\", \n",
    "             \"rummlu\", \n",
    "             \"ruhumaneval\", \n",
    "             \"ruhatespeech\", \n",
    "             \"rcb\", \n",
    "             \"lcs\", \n",
    "             \"bps\", \n",
    "             \"rudetox\", \n",
    "             \"ruethics\", \n",
    "             \"ruhhh\", \n",
    "             \"use\", \n",
    "             \"parus\", \n",
    "             \"mathlogicqa\", \n",
    "             \"ruopenbookqa\", \n",
    "             \"ruworldtree\", \n",
    "             \"multiq\", \n",
    "             \"chegeka\"]\n",
    "\n",
    "i = 5\n",
    "DATASET_PATH = \"ai-forever/MERA\"\n",
    "DATASET_NAME = f\"{task_name[i]}\"\n",
    "df = load_dataset(DATASET_PATH, \n",
    "                  DATASET_NAME, download_mode=\"force_redownload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7947d9ba-eb6d-4c37-817e-87edd8c2761b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'inputs', 'outputs', 'meta'],\n",
       "        num_rows: 10033\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'inputs', 'outputs', 'meta'],\n",
       "        num_rows: 961\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e03d6d9e-2c76-4b36-8b07-c8c4f03cee4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>inputs</th>\n",
       "      <th>outputs</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Задание содержит вопрос по теме {subject} и 4 ...</td>\n",
       "      <td>{'text': 'В какой из этих двух ситуаций действ...</td>\n",
       "      <td>B</td>\n",
       "      <td>{'domain': 'moral_scenarios', 'id': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Задание содержит вопрос по теме {subject} и 4 ...</td>\n",
       "      <td>{'text': 'В какой из этих двух ситуаций действ...</td>\n",
       "      <td>C</td>\n",
       "      <td>{'domain': 'moral_scenarios', 'id': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ниже приведен вопрос на определенную профессио...</td>\n",
       "      <td>{'text': 'В какой из этих двух ситуаций действ...</td>\n",
       "      <td>C</td>\n",
       "      <td>{'domain': 'moral_scenarios', 'id': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Найдите правильный ответ на вопрос по теме {su...</td>\n",
       "      <td>{'text': 'В какой из этих двух ситуаций действ...</td>\n",
       "      <td>A</td>\n",
       "      <td>{'domain': 'moral_scenarios', 'id': 3}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "1  Задание содержит вопрос по теме {subject} и 4 ...   \n",
       "2  Ниже приведен вопрос на определенную профессио...   \n",
       "3  Найдите правильный ответ на вопрос по теме {su...   \n",
       "\n",
       "                                              inputs outputs  \\\n",
       "0  {'text': 'В какой из этих двух ситуаций действ...       B   \n",
       "1  {'text': 'В какой из этих двух ситуаций действ...       C   \n",
       "2  {'text': 'В какой из этих двух ситуаций действ...       C   \n",
       "3  {'text': 'В какой из этих двух ситуаций действ...       A   \n",
       "\n",
       "                                     meta  \n",
       "0  {'domain': 'moral_scenarios', 'id': 0}  \n",
       "1  {'domain': 'moral_scenarios', 'id': 1}  \n",
       "2  {'domain': 'moral_scenarios', 'id': 2}  \n",
       "3  {'domain': 'moral_scenarios', 'id': 3}  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'].to_pandas().head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a33d1400-1aeb-4fe6-8c9d-c466be81690e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = df['train'].to_pandas().loc[300]\n",
    "prompt = doc[\"instruction\"].format(**doc[\"inputs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32d266f5-883e-4578-841c-0a995b407400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'professional_medicine'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rummlu evaluation by domain:\n",
    "domain = doc[\"meta\"][\"domain\"]\n",
    "domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9042ced-1b95-4ed4-8f27-71539511bbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Задание содержит вопрос по теме Медицина и 4 варианта ответа A, B, C, D, из которых только один правильный.\n",
      "4-летнего мальчика доставили к врачу из-за температуры до 39,4°C (102,9°F) в течение 8 дней. Обследование показывает переднюю шейную лимфаденопатию, двусторонний неэкссудативный конъюнктивит, земляничный язык, эритематозную сыпь на туловище и отек кистей и стоп. Какая из перечисленных ниже фармакотерапий является наиболее подходящей для предотвращения осложнений этого заболевания?\n",
      "A Внутривенное введение иммуноглобулина\n",
      "B Пенициллин для внутривенного введения\n",
      "C Внутривенное введение преднизолона\n",
      "D Пероральный изониазид\n",
      "Запишите букву правильного ответа\n",
      "Ответ:\n"
     ]
    }
   ],
   "source": [
    "# model query\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81c604-ec6b-4864-8c7d-f30519321b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[\"meta\"][\"domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e82235a3-7254-49f4-8d8f-bae8a68cfc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a030b68-4f22-4b5e-9224-a195694528db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = torch.tensor(tokenizer(prompt)['input_ids']).long().unsqueeze(0).to(device)\n",
    "out = model.generate(tokens).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1a0b3e6-cb48-4e96-9133-03b0dc707cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Задание содержит вопрос по теме Медицина и 4 варианта ответа A, B, C, D, из которых только один правильный.\n",
      "4-летнего мальчика доставили к врачу из-за температуры до 39,4°C (102,9°F) в течение 8 дней. Обследование показывает переднюю шейную лимфаденопатию, двусторонний неэкссудативный конъюнктивит, земляничный язык, эритематозную сыпь на туловище и отек кистей и стоп. Какая из перечисленных ниже фармакотерапий является наиболее подходящей для предотвращения осложнений этого заболевания?\n",
      "A Внутривенное введение иммуноглобулина\n",
      "B Пенициллин для внутривенного введения\n",
      "C Внутривенное введение преднизолона\n",
      "D Пероральный изониазид\n",
      "Запишите букву правильного ответа\n",
      "Ответ: C\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b82df17d-cbe8-4524-bee6-626e4f99b4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.dataset import MERA_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cce3b414-cc6e-47e7-ba1d-9b6e4c83e5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mMERA_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/artemb/kursach/src/dataset.py:6\u001b[0m, in \u001b[0;36mMERA_dataset.__init__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.mlspace/envs/graph_venv/lib/python3.9/site-packages/datasets/dataset_dict.py:61\u001b[0m, in \u001b[0;36mDatasetDict.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, k) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, (\u001b[38;5;28mstr\u001b[39m, NamedSplit)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 61\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m         available_suggested_splits \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     64\u001b[0m             split \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m (Split\u001b[38;5;241m.\u001b[39mTRAIN, Split\u001b[38;5;241m.\u001b[39mTEST, Split\u001b[38;5;241m.\u001b[39mVALIDATION) \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m     65\u001b[0m         ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prompt'"
     ]
    }
   ],
   "source": [
    "data = MERA_dataset(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-graph_venv]",
   "language": "python",
   "name": "conda-env-.mlspace-graph_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
